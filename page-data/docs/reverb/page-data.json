{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/docs/reverb","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"audio mus-407 digital-audio delay\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"reverb\"\n  }, \"Reverb\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Reverb\"), \", or \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"reverberation\"), \", is a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/fixed-delay-effectsorfixed-delay-effect\",\n    \"title\": \"fixed-delay-effects|fixed delay effect\"\n  }, \"[[fixed-delay-effects|fixed delay effect]]\"), \" where many delay lines work together to simulate reflections of a sound source in order to simulate room/hall acoustics.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"numerous reverb \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/algorithmoralgorithms\",\n    \"title\": \"algorithm|algorithms\"\n  }, \"[[algorithm|algorithms]]\"), \" in existence\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"usually, a large combination of \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/feedback\",\n    \"title\": \"feedback\"\n  }, \"[[feedback]]\"), \" delays with different short/medium delay times, in parallel and series\")), mdx(\"p\", null, \"Delay times usually do not vary dynamically\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"because room dimensions do not vary dynamically!\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"variable delay times can be used for doppler effect and other weird, custom reverb-like effects\")), mdx(\"p\", null, \"Many reverb algorithms are variations on the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Schroeder Reverb\"), \" design:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"4 summed \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/comb-filterorcomb-filters\",\n    \"title\": \"comb-filter|comb filters\"\n  }, \"[[comb-filter|comb filters]]\"), \" in parallel, through two \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/all-pass-filterorall-pass-filters\",\n    \"title\": \"all-pass-filter|all-pass filters\"\n  }, \"[[all-pass-filter|all-pass filters]]\"), \" in series\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"comb filters provide reverb \\\"body\\\"\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"delay lines with \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/feedback\",\n    \"title\": \"feedback\"\n  }, \"[[feedback]]\"), \"\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/all-pass-filterorall-pass-filters\",\n    \"title\": \"all-pass-filter|all-pass filters\"\n  }, \"[[all-pass-filter|all-pass filters]]\"), \" introduce \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/frequency\",\n    \"title\": \"frequency\"\n  }, \"[[frequency]]\"), \"-specific \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/phase\",\n    \"title\": \"phase\"\n  }, \"[[phase]]\"), \" shifts to diffuse the sound and reduce \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/resonance\",\n    \"title\": \"resonance\"\n  }, \"[[resonance]]\"), \"\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/brain/static/5d5faae17519253f784a0c3a38da2b57/ef3e1/schroeder-reverb-design.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"42.142857142857146%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA/ElEQVQY042QS2uDUBSE/f//QTeabozdKIKrIBiXgvhaq7eiphDfeqNXO5g+QhdpZyHe4Zz5mMOxZdm2jd5uwzDYtn08Kpqm1XU97/5zcfflcRzxjePY87wgCBBEKf17mdKJMYbprutM05QkSVFeq6qapqksS0JIkiRN07Rtm0JJWhTFsixsF0dIeq2ufd8jCXNhGEZRBGye57qui6IoCILruo7jHA4vPM8bhpFlGXlLL+8XbplnrIHzQFYQBweQdBdOADKi8Y9QkFe2Qj+d8UBn3/cB/2/nz2tTCvL5bMmyrKoqOs/zvH4JA+uDfi/fLdz5dDpZlgXyt/lEHz/FvXRiEgYOAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Schroeder reverb design\",\n    \"title\": \"Schroeder reverb design\",\n    \"src\": \"/brain/static/5d5faae17519253f784a0c3a38da2b57/410f3/schroeder-reverb-design.png\",\n    \"srcSet\": [\"/brain/static/5d5faae17519253f784a0c3a38da2b57/0d3e1/schroeder-reverb-design.png 140w\", \"/brain/static/5d5faae17519253f784a0c3a38da2b57/6b1e2/schroeder-reverb-design.png 281w\", \"/brain/static/5d5faae17519253f784a0c3a38da2b57/410f3/schroeder-reverb-design.png 561w\", \"/brain/static/5d5faae17519253f784a0c3a38da2b57/ef3e1/schroeder-reverb-design.png 759w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"mus-407\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"feedback\"\n  }, \"Feedback\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feedback\"), \" is a signal processing phenomenon where a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/audio-signalorsignal\",\n    \"title\": \"audio-signal|signal\"\n  }, \"[[audio-signal|signal]]\"), \"'s output is \\\"fed back\\\" into its own input.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"can be considered unstable if not handled properly\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"cd28f42f-e1f1-5d0f-b9c4-371721c2157a","fields":{"slug":"/docs/feedback","title":"Feedback"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"mus-407 sound sound-properties frequency\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"frequency\"\n  }, \"Frequency\"), mdx(\"p\", null, \"The \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"frequency\"), \" of a periodic waveform is the number of cycles that occur per second, measured in Hertz (Hz)\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"periodic waveform\"), \": cyclic behavior, repeatedly exhibits the same pattern\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"non-period/aperiodic\"), \" waveform: irregular, non-repeating pattern\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"also called \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"/noise\",\n    \"title\": \"noise\"\n  }, \"[[noise]]\"), \", unwanted sound\"))))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"period:\"), \" duration, in seconds, of one full cycle of a periodic waveform\"), mdx(\"p\", null, \"inverse relationship between frequency and period: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"f = 1 / p\")), mdx(\"h2\", {\n    \"id\": \"relationship\"\n  }, \"Relationship\"), mdx(\"p\", null, \"Below is the mathematical relationship between speed of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sound-wavesorsound\",\n    \"title\": \"sound-waves|sound\"\n  }, \"[[sound-waves|sound]]\"), \", frequency, and wavelength\"), mdx(\"p\", null, \"$$v = f \\\\lambda$$\"), mdx(\"p\", null, \"v: speed of sound (meters/second)\"), mdx(\"p\", null, \"f: frequency (cycles/second)\"), mdx(\"p\", null, \"$\\\\lambda$: wavelength (meters/cycles)\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"1007ca48-c6ac-51ef-bcd5-e9bfe6322d2e","fields":{"slug":"/docs/frequency","title":"Frequency"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"mus-407 sound sound-properties beating phase\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"phase\"\n  }, \"Phase\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Phase\"), \" refers to a specific point within one cycle of a periodic wave.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"the initial phase of a periodic waveform has essentially no effect on our perception of such a wave, including \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/sound-wavesorsound-waves\",\n    \"title\": \"sound-waves|sound waves\"\n  }, \"[[sound-waves|sound waves]]\"), \"\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"however, multiple sound waves can result in \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/beating\",\n    \"title\": \"beating\"\n  }, \"[[beating]]\"), \"\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"one cycle = 360 degrees = 2\\u03C0 radians\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"c9f3ddec-7c8a-5f6e-bdb4-623f80e77162","fields":{"slug":"/docs/phase","title":"Phase"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"mus-407\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"resonance\"\n  }, \"Resonance\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Resonance\"), \" (in sound) is the boosting of certain \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/frequencyorfrequencies\",\n    \"title\": \"frequency|frequencies\"\n  }, \"[[frequency|frequencies]]\"), \" depending on various characteristics of the sound's medium or nature.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"0b1ae3c9-95f1-5de4-bc23-342b5fa6fa1d","fields":{"slug":"/docs/resonance","title":"Resonance"}}}],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"music production composition composer composers-forum rhythmicity hybridity electroacoustic acoustic sound-design\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"rhythmicity-and-hybridity\"\n  }, \"Rhythmicity and Hybridity\"), mdx(\"p\", null, \"An illusory duality between the acoustic and the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/electroacoustic-musicorelectroacoustic\",\n    \"title\": \"electroacoustic-music|electroacoustic\"\n  }, \"[[electroacoustic-music|electroacoustic]]\"), \"\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"affects the way we perceive acoustic vs electro acoustic writing\")), mdx(\"p\", null, \"\\\"It\\u2019s all about rhythm.\\\"\"), mdx(\"p\", null, \"Talk by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://stylianosdimou.com/\"\n  }, \"Stylianos DIMOU\"), \".\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/music-compositionorcomposer\",\n    \"title\": \"music-composition|composer\"\n  }, \"[[music-composition|composer]]\"), \" of acoustic, electroacoustic, & acousmatic music\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sound designer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"improviser\")), mdx(\"h2\", {\n    \"id\": \"duality\"\n  }, \"Duality\"), mdx(\"p\", null, \"There exists a duality between the experiences of life and creativity.\"), mdx(\"h3\", {\n    \"id\": \"life\"\n  }, \"Life\"), mdx(\"p\", null, \"Emulating the energy of the world\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"nature, ocean, sketching, free-diving\")), mdx(\"h3\", {\n    \"id\": \"creativity\"\n  }, \"Creativity\"), mdx(\"p\", null, \"Metaphysical dialogue with my surroundings\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"music, painting, complexity, multi dimensional intricacies\")), mdx(\"p\", null, \"An experience in one aspect can lead to revelations in the other. Ex. free diving \\u2192 open eyes to multidimensional intricacies of life and experience\"), mdx(\"h2\", {\n    \"id\": \"preliminary-ideas\"\n  }, \"Preliminary Ideas\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"inspiration and raw intuition\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"structure as\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"a liquid\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"as a sculpted organism\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"as a fabric\")))), mdx(\"h2\", {\n    \"id\": \"schema\"\n  }, \"Schema\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Harmony\"), \", the consistency of the whole\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/pitch\",\n    \"title\": \"pitch\"\n  }, \"[[pitch]]\"), \" content, rhythms, electronics, etc.\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Motion\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"thickness, porosity, luminosity, density, elasticity of a sound\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Procedure\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sculpture of sound\\u2014 instrumental \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/sound-synthesisorsynthesis\",\n    \"title\": \"sound-synthesis|synthesis\"\n  }, \"[[sound-synthesis|synthesis]]\"), \", anamorphosis, transformation of the spectral morphology\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Motion and Procedure lead to \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Musical Gesture\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Motion, Procedure, and Musical Gesture lead to \\u201C\", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"STRUCTURE\\u201D\"), \" at the micro or macro scale\")), mdx(\"h2\", {\n    \"id\": \"-on-sound\"\n  }, \".. on sound\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lines and shapes\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"microtonal and multidimensional networks\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"deconstruction of the squareness of \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/TET\",\n    \"title\": \"TET\"\n  }, \"[[TET]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"see: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/microtonal-music\",\n    \"title\": \"microtonal-music\"\n  }, \"[[microtonal-music]]\"), \"\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"liquefied rhythmic and intervallic structures\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"multidimensional domino processes\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"imagine jumping between dimensions of sound\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"amplification resulting to electrified sonic entities\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"a different way to experience music\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"new sonic palette\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"threshold between \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/noise\",\n    \"title\": \"noise\"\n  }, \"[[noise]]\"), \" and pitch\")), mdx(\"h3\", {\n    \"id\": \"main-points\"\n  }, \"Main Points\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"multidimensionality\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"gestures\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"lines\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"liquification\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"microtonality, \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/microtonal-music\",\n    \"title\": \"microtonal-music\"\n  }, \"[[microtonal-music]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"domino\")), mdx(\"h2\", {\n    \"id\": \"simplexity\"\n  }, \"\\\"Simplexity\\\"\"), mdx(\"p\", null, \"Delivering complex solutions in the simplest way possible\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"the necessity to define frameworks of coexistence between complexity and simplicity\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"artistic and technological frameworks that enable technology to be part of the creative process and the performance practice, while being as equally involved as human beings in the realization and final execution of a piece of music, a sound installation, etc.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"in search of a hybrid relationship that can be the ground zero if the reconceptualization of complexity either as a sonic or as a performance practice experience\")), mdx(\"h2\", {\n    \"id\": \"extended-hybridity-of-electrified-soundscapes\"\n  }, \"Extended hybridity of electrified soundscapes\"), mdx(\"p\", null, \"coexistence of multiple acoustic and electronic entities\"), mdx(\"p\", null, \"hybrid sonic twin \\u2014 extending sonic capabilities of acoustic instruments and properties through electronics\"), mdx(\"h2\", {\n    \"id\": \"mixed-electro-acoustic-music\"\n  }, \"mixed, electro acoustic music\"), mdx(\"p\", null, \"acoustic sounds\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"metallic sonic qualities\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"idiomatic frictions\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"granulated textures (see: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/granular-synthesis\",\n    \"title\": \"granular-synthesis\"\n  }, \"[[granular-synthesis]]\"), \")\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"chaotic microtonal clouds\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intricate sonic interconnections\")), mdx(\"p\", null, \"electronics\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"amplification\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"fixed media\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"DSP\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"spatialization of sound\")), mdx(\"h2\", {\n    \"id\": \"extended-acoustics-ir-and-convolution-reverb\"\n  }, \"Extended \\u201Cacoustics\\u201D IR and convolution \", mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \"\"), mdx(\"p\", null, \"grasping the sonic nuances that emerge during the traditional process\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Machine Learning\"), \" - piece focusing on the mechanics of the baritone saxophone\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"6ed4ac60-c5e1-530c-922c-389f7ea83648","fields":{"slug":"/docs/rhythmicity-and-hybridity","title":"Rhythmicity and Hybridity"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"music music-review mus-407\",\n  \"type\": \"music-review\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"pamela-z---suite-for-voice-and-electronics\"\n  }, \"Pamela Z - Suite for Voice and Electronics\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=ebxvVJwGWek\"\n  }, \"Link\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.pamelaz.com/\"\n  }, \"Pamela Z\")), mdx(\"p\", null, \"I found these pieces to be an amazing exploration of the voice and the possible manipulations you can perform with just the voice. Pamela Z utilized the voice in some way for every performance, and each performance had a slightly different usage.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Quatre Couches\"), \" used a combination of many performance aspects Pamela Z uses across all these performances. It seems that she's recording her own voice, storing them as \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sampling-compositionorsamples\",\n    \"title\": \"sampling-composition|samples\"\n  }, \"[[sampling-composition|samples]]\"), \", and affecting those samples with various effects, including \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/digital-delay-lineordelay\",\n    \"title\": \"digital-delay-line|delay\"\n  }, \"[[digital-delay-line|delay]]\"), \", \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \", and looping. To trigger the samples, she uses the electronic device in front of her to detect her hand motions, possibly through light or some other method. Either way, this device allows a minute level of control that she exhibits through her finger motions to create organic changes in the samples. Through these methods, I felt as if Pamela Z presented and developed a motif at the beginning of the piece, then manipulated and developed that motif electronically, which I really enjoyed. It's almost as if every performance of \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Quatre Couches\"), \" will have a slightly different motif since it's recorded each performance, and that motif will be manipulated further through the electronics to create entirely unique experiences each performance.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Badagada\"), \" uses a more rhythmic, looping ostinato sampled at the beginning of the piece, which differs from the more time-fluid form of the previous performance. Unlike \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Quatre Couches\"), \", it seems that \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Badagada\"), \" relies less heavily on pre-recorded samples and the manipulation of samples using the electronic device, and moreso features Pamela Z's live performance and the samples she records during the performance itself.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Typewriter\"), \" uses the electronic device to simulate a physical object through \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sound-wavesorsound\",\n    \"title\": \"sound-waves|sound\"\n  }, \"[[sound-waves|sound]]\"), \" and gesture alone, which was both amusing and interesting. \", \"*\", \"*\", \"This piece really highlights the versatility and creative freedom of the sensor that Pamela Z uses.\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Breathing\"), \" seemed to focus a lot more on the manipulation of recorded samples through more electronic devices, like gloves with gyroscope sensors to sense the angle of Pamela Z's voice to control filtering and looping parameters. Like \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Badagada\"), \", \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Breathing\"), \" highlights live recorded samples primarily.\"), mdx(\"p\", null, \"Overall, I really enjoyed Pamela Z's use of live performance through her voice and the manipulation of live recorded samples with electronics. Having a sensor to sense delicate hand movements seems to offer an amazing level of control, similar to a theremin. I think this method of performance can definitely be explored more, and it pushed my boundaries of what I thought live performance with \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/electroacoustic-musicorelectroacoustic-music\",\n    \"title\": \"electroacoustic-music|electroacoustic music\"\n  }, \"[[electroacoustic-music|electroacoustic music]]\"), \" could be.\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"8d7d9883-456d-54b7-a60e-e0536195fe04","fields":{"slug":"/docs/music-reviews/pamela-z-suite-for-voice-and-electronics","title":"Pamela Z - Suite for Voice and Electronics"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"mus-407 ece-402\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"all-pass-filter\"\n  }, \"All-Pass Filter\"), mdx(\"p\", null, \"An \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"all-pass filter\"), \" is a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sampling-signal-processingorsignal-processing\",\n    \"title\": \"sampling-signal-processing|signal processing\"\n  }, \"[[sampling-signal-processing|signal processing]]\"), \" filter that passes all \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/frequencyorfrequencies\",\n    \"title\": \"frequency|frequencies\"\n  }, \"[[frequency|frequencies]]\"), \" equally in gain but changes the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/phase\",\n    \"title\": \"phase\"\n  }, \"[[phase]]\"), \" relationship among various frequencies.\"), mdx(\"h2\", {\n    \"id\": \"within-reverb\"\n  }, \"Within reverb\"), mdx(\"p\", null, \"In \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \" \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/algorithm\",\n    \"title\": \"algorithm\"\n  }, \"[[algorithm]]\"), \"s, all-pass filters reduce \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/resonance\",\n    \"title\": \"resonance\"\n  }, \"[[resonance]]\"), \" by introducing \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/frequency\",\n    \"title\": \"frequency\"\n  }, \"[[frequency]]\"), \"-specific \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/phase\",\n    \"title\": \"phase\"\n  }, \"[[phase]]\"), \"-shifts to diffuse the sound.\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"7836c779-007e-5a69-ab18-a000879c8be7","fields":{"slug":"/docs/all-pass-filter","title":"All-Pass Filter"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"music music-review mus-407\",\n  \"type\": \"music-review\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"olly-wilson---piano-piece-for-piano-and-electronic-sound-1969\"\n  }, \"Olly Wilson - Piano Piece for piano and electronic sound (1969)\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=ib6-Ytte1k8\"\n  }, \"Link\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://music.berkeley.edu/olly-wilson-1937-2018/\"\n  }, \"Olly Wilson\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.oberlin.edu/news/composer-olly-wilson-founding-father-electronic-music-oberlin-dies-80\"\n  }, \"Article\"))), mdx(\"p\", null, \"Considering that the previous piece by Kyong Mee Choi was also written for piano and electronics, I listened to \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Piano Piece for piano and electronic sound\"), \" by Olly Wilson with the intention of comparing and contrasting the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/music-compositionorcompositional\",\n    \"title\": \"music-composition|compositional\"\n  }, \"[[music-composition|compositional]]\"), \" decisions made by these two composers. Compared to Kyong Mee Choi's \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Dawn and Dusk\"), \", Wilson's electronics sound more distorted and industrial than those in \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Dawn and Dusk\"), \".\"), mdx(\"p\", null, \"Rather than creating an atmosphere using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \" to accentuate the piano parts, Wilson uses electronics almost like another instrument playing in conversation with the piano by using distortion and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/digital-delay-lineordelay\",\n    \"title\": \"digital-delay-line|delay\"\n  }, \"[[digital-delay-line|delay]]\"), \" on the samples. Some notable examples of distortion include high-\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/pitch\",\n    \"title\": \"pitch\"\n  }, \"[[pitch]]\"), \"ed distorted tones at 3:42, mid-range delayed samples near 3:59, and distorted, reverberant parts near 7:57. The piano often imitated these distorted tones with dissonant chords and angular lines, taking full advantage of the piano's spectral range in a way that Choi does in \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Dawn and Dusk\"), \". While I'm not confident in my listening, it does seem like Wilson uses other aspects of the piano other than just the keyboard, such as touching the strings of the piano or using its body as a percussive surface.\"), mdx(\"p\", null, \"Similar to Choi, Wilson also employs a dynamic, developing form for his piece that grows in intensity through dissonance, distortion, and frequency of notes. However, while the medium is the same for both pieces, Wilson invokes a different dynamic between the piano and electronics by having their parts interact more closely together, either playing together or almost playing in call-and-response form. With this piece being written in 1969, I wonder how Wilson was able to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sound-synthesisorsynthesize\",\n    \"title\": \"sound-synthesis|synthesize\"\n  }, \"[[sound-synthesis|synthesize]]\"), \" the electronic sounds he did, and what his thought process was behind composing the piano parts alongside the electronic media.\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"359a575f-3208-5d2b-b8fc-6fdcfbf85c71","fields":{"slug":"/docs/music-reviews/olly-wilson-piano-piece-for-piano-and-electronic-sound","title":"Olly Wilson - Piano Piece for piano and electronic sound (1969)"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"music music-review mus-407\",\n  \"type\": \"music-review\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"kirsten-volness---river-rising\"\n  }, \"Kirsten Volness - River Rising\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=NgyTUIHaBJc\"\n  }, \"Link\")), mdx(\"p\", null, \"Overall, I enjoyed this piece for its evolving atmosphere and combination of violin with stereo \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/digital-audiooraudio\",\n    \"title\": \"digital-audio|audio\"\n  }, \"[[digital-audio|audio]]\"), \" and live electronics. Based on the piece description as well as the overall tone and mood of the piece, I felt a sense of fluctuating emotional toil, as if someone is trying to process and navigate their way through indescribable grief or pain.\"), mdx(\"p\", null, \"The atmosphere throughout the piece comprises of lower \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/frequency\",\n    \"title\": \"frequency\"\n  }, \"[[frequency]]\"), \", drone-like parts alongside more fluid, almost periodic higher frequency parts, which I felt left room for the violin to be heard and highlighted. The first two minutes mostly feature the higher frequency parts with the violin playing alongside, and I interpret the focus of violin as a way to place the violin as the \\\"main character\\\" of this piece, either as a character to be watched or as a way for the listener to insert themselves into the piece.\"), mdx(\"p\", null, \"After the first 2 minutes, the lower frequencies begin to slowly fill the soundscape as the intensity of the parts grows to a climax at around the 3:30 mark, indicated by a more frantic violin part. The dissonance created by the atmospheric parts felt dark and toilsome to me, as if this moment were a turning point in the main character's process of grief.\"), mdx(\"p\", null, \"Near the 5:10 mark, a low noise begins to engulf the soundscape, creating a sense of impending doom or lingering, permeating weight. At around 6:20-6:40, the noise slowly fades out to bring the violin back to the forefront, giving a sense of closure and space to breathe. By this point, the structure of the piece has shown a progression of low to high intensity moments, complemented by density of stereo audio/live electronic parts and the franticness of the violin part.\"), mdx(\"p\", null, \"To create such a spacious, dense atmosphere, I believe Volness may have used generous amounts of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/digital-delay-lineordelay\",\n    \"title\": \"digital-delay-line|delay\"\n  }, \"[[digital-delay-line|delay]]\"), \" to alter an original \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sound-wavesorsound\",\n    \"title\": \"sound-waves|sound\"\n  }, \"[[sound-waves|sound]]\"), \" source, one that was either recorded or generated synthetically. The higher frequency parts seem to blend between recorded, ambient noises from nature or out in the world, and synthesized instruments with heavy effects. It was difficult for me to pinpoint how or where the lower frequency drones could have been created, though I imagine the process was similar to the higher frequency parts. A combination of layering of parts and automation of effects may have been used to create the swelling atmosphere. Overall, I really enjoyed \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"River Rising\"), \" and would be open to studying it further.\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"0841d06b-83ec-5740-ad89-7ce97adbba31","fields":{"slug":"/docs/music-reviews/kirsten-volness-river-rising","title":"Kirsten Volness - River Rising"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"music music-review mus-407\",\n  \"type\": \"music-review\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"kyong-mee-choi---dawn-and-dusk-2012\"\n  }, \"Kyong Mee Choi - Dawn and Dusk (2012)\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=qnVfzAfz2-g\"\n  }, \"Link\")), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kyongmeechoi.com/Main_Site/Home.html\"\n  }, \"Kyong Mee Choi\")), mdx(\"p\", null, \"To me, the most intriguing part of this piece was the use of the piano not necessarily to play precise notes of a particular scale-like structure, but moreso Kyong Mee Choi's decision to take advantage of the dynamic and \\\"spectral\\\" range of the piano. It felt more like she composed for the piano like one would a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/synthesizer\",\n    \"title\": \"synthesizer\"\n  }, \"[[synthesizer]]\"), \" or electronic instrument, focusing more on the range and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/amplitude\",\n    \"title\": \"amplitude\"\n  }, \"[[amplitude]]\"), \" of sounds you could play on the piano rather than the notes themselves.\"), mdx(\"p\", null, \"The sounds from the piano tended to range between short, percussive hits on the high register on the piano during the more ethereal, ambient portions of the piece (the 0:00, 6:00, and 11:30 minute mark), and more drone-like rolling of hands on the keys and strings of the piano in more intense, thicker parts of the piece (3:25, 10:15 minute marks). This dichotomy of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/timbre\",\n    \"title\": \"timbre\"\n  }, \"[[timbre]]\"), \"s is often bridged by transitional moments of arpeggios and electronic textures mixing with those of the piano, creating a sweep and swell that highlights a moving structure throughout the piece.\"), mdx(\"p\", null, \"The electronics included with the piece do really well to accentuate the piano performance, creating noise and sparse tones to create a more \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \"erant sound throughout the entire piece and fill lots of space - I imagined a large, open field as a visual \\\"setting\\\" for a piece like this. Many of the sounds from the electronics felt like the sounds of real objects manipulated to great effect - while the sounds themselves sounded industrial and hollow-like, the movement of these sounds felt more organic.\"), mdx(\"p\", null, \"I really enjoyed the use of the double pianos and how immense yet serene they can sound when combined with the electronics. I would like to study this piece more to find more closely-linked motifs or themes, as well as learn more about the compositional, creative, and technical processes that went into creating this piece.\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"6dbaea27-66fc-5990-81e1-cd4ed5a8a074","fields":{"slug":"/docs/music-reviews/kyong-mee-choi-from-dawn-to-dusk","title":"Kyong Mee Choi - Dawn and Dusk (2012)"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"music hyperpop genre production\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"hyperpop\"\n  }, \"Hyperpop\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Hyperpop\"), \" is a \\\"microgenre\\\" focusing on exaggerating elements from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/popular-musicorpopular-music\",\n    \"title\": \"popular-music|popular music\"\n  }, \"[[popular-music|popular music]]\"), \". Some hyperpop artists include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"100 gecs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sophie\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dorian Electra\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Alice Longyu Gao\")), mdx(\"h2\", {\n    \"id\": \"common-instruments\"\n  }, \"Common Instruments\"), mdx(\"p\", null, \"Since hyperpop serves as an exaggerated take on popular music, it uses many fundamental elements found in popular music but in \\\"exaggerated ways\\\":\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Piano, guitar\"), \": usually \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/sampling-compositionorsamples\",\n    \"title\": \"sampling-composition|samples\"\n  }, \"[[sampling-composition|samples]]\"), \", spliced or \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/pitch\",\n    \"title\": \"pitch\"\n  }, \"[[pitch]]\"), \"-shifted drastically\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Drums\"), \": \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/hip-hop\",\n    \"title\": \"hip-hop\"\n  }, \"[[hip-hop]]\"), \"/\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/pop-musicorpop\",\n    \"title\": \"pop-music|pop\"\n  }, \"[[pop-music|pop]]\"), \" drums, sampled and distorted/saturated\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"808s\"), \": distorted/saturated, often to an extent most radio pop music would avoid\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"Earworm\\\" \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"vocals\"), \" with heavy effects, heavily layered and \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/pitch-shiftingorpitch-shifted\",\n    \"title\": \"pitch-shifting|pitch-shifted\"\n  }, \"[[pitch-shifting|pitch-shifted]]\"), \" beyond realism\")), mdx(\"h2\", {\n    \"id\": \"form\"\n  }, \"Form\"), mdx(\"p\", null, \"The form of hyperpop songs varies drastically across artists and groups; these current notes are only based on one analysis from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=94l5jJ200rU\"\n  }, \"how to hyperpop (class_shift)\"), \".\"), mdx(\"h3\", {\n    \"id\": \"intro\"\n  }, \"Intro\"), mdx(\"p\", null, \"TODO: expand past notes taken from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=94l5jJ200rU\"\n  }, \"how to hyperpop (class_shift)\")), mdx(\"p\", null, \"Hyperpop intros usually begin with a simple sample of 1-2 instruments, focusing on a core idea that gets manipulated or developed throughout the song.\"), mdx(\"p\", null, \"Elements used:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"piano/guitar\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"synths\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"simple \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/sine-waveorsine\",\n    \"title\": \"sine-wave|sine\"\n  }, \"[[sine-wave|sine]]\"), \"/\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/square-waveorsquare\",\n    \"title\": \"square-wave|square\"\n  }, \"[[square-wave|square]]\"), \" waves\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"atmospheric, \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \"/\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/digital-delay-lineordelay\",\n    \"title\": \"digital-delay-line|delay\"\n  }, \"[[digital-delay-line|delay]]\"), \"-heavy pads\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"vocals\")), mdx(\"h3\", {\n    \"id\": \"chorus\"\n  }, \"Chorus\"), mdx(\"p\", null, \"Hyperpop choruses are characterized by \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"808s\"), \", heavy \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"distortion\"), \", and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"exaggerated vocals\"), \".\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"808s\"), \": within hyperpop, most artists either pitch-shift samples or create their own presents/patches for more control on the 808's sound.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"characterized by heavy distortion\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"at its core: every 808 is a \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/kick\",\n    \"title\": \"kick\"\n  }, \"[[kick]]\"), \" and a distorted \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/sine-wave\",\n    \"title\": \"sine-wave\"\n  }, \"[[sine-wave]]\"), \" played at the same time\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"many artists make their 808s \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"wide\"), \", spreading across the stereo field\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Vocals\"), \": hyperpop vocals utilize heavy layering and effects, forgoing realism and transparency for stylistic flair and exaggeration\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"vocals are often layered; if not, they employ heavy effect chains:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"multiband \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/compression\",\n    \"title\": \"compression\"\n  }, \"[[compression]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"distortion\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"autotune\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \"\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"when layered, vocals are usually harmonized in octaves and thirds (both above/below, depending on what's usually diatonic)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"harmonies usually panned left + right for a wider sound\")))), mdx(\"h2\", {\n    \"id\": \"transitions\"\n  }, \"Transitions\"), mdx(\"p\", null, \"Transitions used in hyperpop are similar to those used in pop, but exaggerated. These include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"LPF automation on the mix before the chorus to create a \\\"future bass chord\\\" type texture\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dropping the bass or soloing the vocals before and after the chorus to increase contrast\")));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"4cb092a5-8ce8-5a24-8176-ba3fcd9d83f4","fields":{"slug":"/docs/hyperpop","title":"Hyperpop"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": \"ece-402 dsp spectral-analysis\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"short-window-time-varying-spectral-analysis\"\n  }, \"Short Window Time-Varying Spectral Analysis\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Short Window Time-Varying Spectral Analysis\"), \" is a form of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/time-varying-spectral-analysisortime-varying-spectral-analysis\",\n    \"title\": \"time-varying-spectral-analysis|time-varying spectral analysis\"\n  }, \"[[time-varying-spectral-analysis|time-varying spectral analysis]]\"), \" that analyzes only a short segment of a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/audio-signalorsignal\",\n    \"title\": \"audio-signal|signal\"\n  }, \"[[audio-signal|signal]]\"), \", rather than the entire signal.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"models how the human ear analyzes \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/frequencyorfrequencies\",\n    \"title\": \"frequency|frequencies\"\n  }, \"[[frequency|frequencies]]\"), \" over short segments of \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/sound-wavesorsound\",\n    \"title\": \"sound-waves|sound\"\n  }, \"[[sound-waves|sound]]\"), \" (about 10-20 ms in length)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"used to perform \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/spectral-analysisorspectral-analysis\",\n    \"title\": \"spectral-analysis|spectral analysis\"\n  }, \"[[spectral-analysis|spectral analysis]]\"), \" comparable to human hearing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"pitch-synchronous, results in good-time resolution and prevents temporal smearing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"short-window artifacts include cross-talk between frequencies and \\\"ripple\\\" effects\")), mdx(\"p\", null, \"The proper way to extract a short signal segment is to multiply the longer, original signal by a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/spectrum-analysis-windoworwindow-function\",\n    \"title\": \"spectrum-analysis-window|window function\"\n  }, \"[[spectrum-analysis-window|window function]]\"), \".\"), mdx(\"p\", null, \"Short window analysis is best for monophonic, \\\"quasi-harmonic\\\" input sounds.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"quasi-harmonic\"), \": \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/partial\",\n    \"title\": \"partial\"\n  }, \"[[partial]]\"), \"s of the sound should be very close to integer multiples of the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/fundamental\",\n    \"title\": \"fundamental\"\n  }, \"[[fundamental]]\"), \"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"for best results, recording should have as little \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/reverb\",\n    \"title\": \"reverb\"\n  }, \"[[reverb]]\"), \" as possible\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"for the sake of analysis, reverb makes a monophonic sound polyphonic!\")), mdx(\"h2\", {\n    \"id\": \"procedure\"\n  }, \"Procedure\"), mdx(\"p\", null, \"The following steps are a loose outline of performing short window analysis:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Detect pitch of waveform (or ask user)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Select window, which is related pitch period (usually a two-period window), as well as a hope size\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Compute amplitude and phase at each window (also referred to as \\\"grain\\\")\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"String together $A_n(t_0 + m \\\\times N)$ to get amplitude envelope for partial $n$\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Perform frequency correction from phase values\")), mdx(\"p\", null, \"Use of a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"two-period raised-cosine window\"), \":\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"all parts of the period are weighted the same\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"assume \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/spectrum\",\n    \"title\": \"spectrum\"\n  }, \"[[spectrum]]\"), \" does not change much within the short window\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"each window could be thought of as a \\\"grain\\\"\")), mdx(\"h3\", {\n    \"id\": \"mathematics\"\n  }, \"Mathematics\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$s(t)$: input signal to be analyzed, where $t$ is the sample number ($t$ is time in units of $\\\\frac{1}{SR}$)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$h(i)$: 2-period window\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$N$: input signal's period i samples, rounded to nearest integer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$f$: frequency in Hz corresponding to period $N$, computed by $f = SR / N$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$n$: partial number ($n=1$ is fundamental), $1 \\\\leq n \\\\leq N/2$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$a\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"n(t)$: \\\"sine coefficient\\\" for partial $n$ at time $t$, computed using two periods of windowed input data centered at sample $t$\\n$$\\na_n(t) = \\\\sum^N\"), \"{i=-N}s(i+t) \\\\cdot h(i) \\\\cdot sin(2 \\\\pi nfi / N)\\n$$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$b\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"n(t)$: \\\"cosine coefficient\\\" for partial $n$ at time $t$, computed using two periods of windowed input data centered at sample $t$\\n$$\\nb_n(t) = \\\\sum^N\"), \"{i=-N}s(i+t) \\\\cdot h(i) \\\\cdot cos(2 \\\\pi nfi / N)\\n$$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$A_n(t)$: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/amplitude\",\n    \"title\": \"amplitude\"\n  }, \"[[amplitude]]\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/envelope\",\n    \"title\": \"envelope\"\n  }, \"[[envelope]]\"), \" value for partial $n$ at time $t$\\n$$\\nA_n(t) = \\\\sqrt{a^2_n(t) + b^2_n(t)}\\n$$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$\\\\theta_n(t)$: phase value for partial $n$ at time $t$\\n$$\\n\\\\theta_n(t) = atan(\\\\frac{a_n(t)}{b_n(t)})\\n$$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$F_n(t)$: frequency envelope value for partial $n$ at time $t$\\n$$\\nF_n(t) = n \\\\cdot (f + \\\\theta_n ' (t))\\n$$\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"$\\\\Delta t$: hop size; usually $\\\\Delta t = N$; $A_n(t)$ and $F_n(t)$ will be computed for $t =$ integer multiples of $t$\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"during synthesis, linear interpolation will be done between these computed values of $A_n(t)$ and $F_n(t)$\")))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"561px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/brain/static/1d82e36b879ecfb5b9df10fa2ed5c3d2/ae6b7/short-window.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"30.714285714285715%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABHElEQVQY0xWOiWrDMBBE/e+hcZtCS1MH4sTWZVnH6pZsB9LQ/loVWIZh2TezjRbi53H33lsfuTZcAVdVLWKCzZLxKQS3LSWnUFJccy4xeGvkPFuARjBWllhKfvz+SefpLJRz0lgIkUwCU1qWfFtLcM4BgJLVbGvZSgGlm4mQZ/a65HUL282Emr8p702IV0x9ysYYhEaCB4rRte8ZIUqIWA9q80SoAeks+BiZAu3jdn+4XKRzVCifUsqhjrVaV4hzTllF5okThCqM4bll2hibsrZ+1oZJxTUoV73SoKWcCR7ReBmHKx4HgkZQahiHpj99c0aWFIVWlIvu3NcfXF66/rLbt1/HjhCCMeq646F93b/s3tr2+PlxPnXvh8M/ax7qtEJhsPEAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Short window\",\n    \"title\": \"Short window\",\n    \"src\": \"/brain/static/1d82e36b879ecfb5b9df10fa2ed5c3d2/410f3/short-window.png\",\n    \"srcSet\": [\"/brain/static/1d82e36b879ecfb5b9df10fa2ed5c3d2/0d3e1/short-window.png 140w\", \"/brain/static/1d82e36b879ecfb5b9df10fa2ed5c3d2/6b1e2/short-window.png 281w\", \"/brain/static/1d82e36b879ecfb5b9df10fa2ed5c3d2/410f3/short-window.png 561w\", \"/brain/static/1d82e36b879ecfb5b9df10fa2ed5c3d2/ae6b7/short-window.png 655w\"],\n    \"sizes\": \"(max-width: 561px) 100vw, 561px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"sources\"\n  }, \"Sources\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://ccrma.stanford.edu/~jos/sasp/Spectrum_Analysis_Windows.html\"\n  }, \"https://ccrma.stanford.edu/~jos/sasp/Spectrum_Analysis_Windows.html\"))));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"2786433c-ade0-5abc-a1f2-0ad8f8f571e6","fields":{"slug":"/docs/short-window-time-varying-spectral-analysis","title":"Short Window Time-Varying Spectral Analysis"}}}]},"fields":{"slug":"/docs/reverb","title":"Reverb"}}},"pageContext":{"id":"70031306-0796-5757-b573-9bbb6f3c2e89"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}